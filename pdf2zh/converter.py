import concurrent.futures
import logging
import re
import unicodedata
from enum import Enum
from string import Template
from typing import Dict, List

import numpy as np
from pdfminer.converter import PDFConverter
from pdfminer.layout import LTChar, LTFigure, LTLine, LTPage
from pdfminer.pdffont import PDFCIDFont, PDFUnicodeNotDefined
from pdfminer.pdfinterp import PDFGraphicState, PDFResourceManager
from pdfminer.utils import apply_matrix_pt, mult_matrix
from pymupdf import Font
from tenacity import retry, wait_fixed

from pdf2zh.config import ConfigManager
from pdf2zh.text_shaper import get_text_shaper
from pdf2zh.translator import (
    AnythingLLMTranslator,
    ArgosTranslator,
    AzureOpenAITranslator,
    AzureTranslator,
    BaseTranslator,
    BingTranslator,
    DeepLTranslator,
    DeepLXTranslator,
    DeepseekTranslator,
    DifyTranslator,
    GeminiTranslator,
    GoogleTranslator,
    GrokTranslator,
    GroqTranslator,
    ModelScopeTranslator,
    OllamaTranslator,
    OpenAIlikedTranslator,
    OpenAITranslator,
    QwenMtTranslator,
    SiliconTranslator,
    TencentTranslator,
    XinferenceTranslator,
    ZhipuTranslator,
    X302AITranslator,
)

log = logging.getLogger(__name__)


class PDFConverterEx(PDFConverter):
    def __init__(
        self,
        rsrcmgr: PDFResourceManager,
    ) -> None:
        PDFConverter.__init__(self, rsrcmgr, None, "utf-8", 1, None)

    def begin_page(self, page, ctm) -> None:
        # é‡è½½æ›¿æ¢ cropbox
        (x0, y0, x1, y1) = page.cropbox
        (x0, y0) = apply_matrix_pt(ctm, (x0, y0))
        (x1, y1) = apply_matrix_pt(ctm, (x1, y1))
        mediabox = (0, 0, abs(x0 - x1), abs(y0 - y1))
        self.cur_item = LTPage(page.pageno, mediabox)

    def end_page(self, page):
        # é‡è½½è¿”å›æŒ‡ä»¤æµ
        return self.receive_layout(self.cur_item)

    def begin_figure(self, name, bbox, matrix) -> None:
        # é‡è½½è®¾ç½® pageid
        self._stack.append(self.cur_item)
        self.cur_item = LTFigure(name, bbox, mult_matrix(matrix, self.ctm))
        self.cur_item.pageid = self._stack[-1].pageid

    def end_figure(self, _: str) -> None:
        # é‡è½½è¿”å›æŒ‡ä»¤æµ
        fig = self.cur_item
        assert isinstance(self.cur_item, LTFigure), str(type(self.cur_item))
        self.cur_item = self._stack.pop()
        self.cur_item.add(fig)
        return self.receive_layout(fig)

    def render_char(
        self,
        matrix,
        font,
        fontsize: float,
        scaling: float,
        rise: float,
        cid: int,
        ncs,
        graphicstate: PDFGraphicState,
    ) -> float:
        # é‡è½½è®¾ç½® cid å’Œ fon
        try:
            text = font.to_unichr(cid)
            assert isinstance(text, str), str(type(text))
        except PDFUnicodeNotDefined:
            text = self.handle_undefined_char(font, cid)
        textwidth = font.char_width(cid)
        textdisp = font.char_disp(cid)
        item = LTChar(
            matrix,
            font,
            fontsize,
            scaling,
            rise,
            text,
            textwidth,
            textdisp,
            ncs,
            graphicstate,
        )
        self.cur_item.add(item)
        item.cid = cid  # hack æ’å…¥åŸå­—ç¬¦ç¼–ç 
        item.font = font  # hack æ’å…¥åŸå­—ç¬¦å­—ä½“
        return item.adv


class Paragraph:
    def __init__(self, y, x, x0, x1, y0, y1, size, brk):
        self.y: float = y  # åˆå§‹çºµåæ ‡
        self.x: float = x  # åˆå§‹æ¨ªåæ ‡
        self.x0: float = x0  # å·¦è¾¹ç•Œ
        self.x1: float = x1  # å³è¾¹ç•Œ
        self.y0: float = y0  # ä¸Šè¾¹ç•Œ
        self.y1: float = y1  # ä¸‹è¾¹ç•Œ
        self.size: float = size  # å­—ä½“å¤§å°
        self.brk: bool = brk  # æ¢è¡Œæ ‡è®°


# fmt: off
class TranslateConverter(PDFConverterEx):
    def __init__(
        self,
        rsrcmgr,
        vfont: str = None,
        vchar: str = None,
        thread: int = 0,
        layout={},
        lang_in: str = "",
        lang_out: str = "",
        service: str = "",
        noto_name: str = "",
        noto: Font = None,
        envs: Dict = None,
        prompt: Template = None,
        ignore_cache: bool = False,
    ) -> None:
        super().__init__(rsrcmgr)
        self.vfont = vfont
        self.vchar = vchar
        self.thread = thread
        self.layout = layout
        self.noto_name = noto_name
        self.noto = noto
        self.text_shaper = get_text_shaper()
        self.translator: BaseTranslator = None
        # e.g. "ollama:gemma2:9b" -> ["ollama", "gemma2:9b"]
        param = service.split(":", 1)
        service_name = param[0]
        service_model = param[1] if len(param) > 1 else None
        if not envs:
            envs = {}
        for translator in [GoogleTranslator, BingTranslator, DeepLTranslator, DeepLXTranslator, OllamaTranslator, XinferenceTranslator, AzureOpenAITranslator,
                           OpenAITranslator, ZhipuTranslator, ModelScopeTranslator, SiliconTranslator, GeminiTranslator, AzureTranslator, TencentTranslator, DifyTranslator, AnythingLLMTranslator, ArgosTranslator, GrokTranslator, GroqTranslator, DeepseekTranslator, OpenAIlikedTranslator, QwenMtTranslator, X302AITranslator]:
            if service_name == translator.name:
                self.translator = translator(lang_in, lang_out, service_model, envs=envs, prompt=prompt, ignore_cache=ignore_cache)
        if not self.translator:
            raise ValueError("Unsupported translation service")

    def _get_font_path(self, font_name: str) -> str:
        """Get font file path for text shaping."""
        if font_name == self.noto_name:
            # Use the Noto font path from config
            noto_path = ConfigManager.get("NOTO_FONT_PATH")
            if noto_path:
                return noto_path

        # For other fonts, we would need to map them to actual font files
        # For now, fallback to the Noto fon
        noto_path = ConfigManager.get("NOTO_FONT_PATH")
        return noto_path if noto_path else ""

    def _shape_text_run(self, text: str, font_name: str, font_size: float, scaled_font_size: float) -> List[Dict]:
        """
        Shape a text run and return detailed glyph positioning information.

        Args:
            text: Text to shape
            font_name: Font identifier
            font_size: Original font size
            scaled_font_size: Scaled font size for rendering

        Returns:
            List of glyph dictionaries with positioning information
        """
        # Try HarfBuzz shaping first for complex scripts
        font_path = self._get_font_path(font_name)

        # Check if text needs complex shaping
        needs_shaping = self.text_shaper._needs_shaping(text) if self.text_shaper.enabled else False

        if font_path and self.text_shaper.enabled and len(text) > 0:
            log.debug(f"ğŸ” Checking text '{text}' (font: {font_name}, needs_shaping: {needs_shaping})")

            shaped_text = self.text_shaper.shape_text(text, font_path, scaled_font_size)
            if shaped_text and shaped_text.success:
                # Convert HarfBuzz glyphs to our format
                glyphs = []
                for glyph in shaped_text.glyphs:
                    glyphs.append({
                        'glyph_id': glyph.glyph_id,
                        'cluster': glyph.cluster,
                        'x_advance': glyph.x_advance,
                        'y_advance': glyph.y_advance,
                        'x_offset': glyph.x_offset,
                        'y_offset': glyph.y_offset,
                        'char_index': glyph.cluster if glyph.cluster < len(text) else 0
                    })
                log.info(f"ğŸ‡¹ğŸ‡­ THAI SHAPING SUCCESS: '{text}' -> {len(glyphs)} glyphs (advance: {shaped_text.total_advance:.2f}pt)")

                # Log detailed glyph information for Thai text
                if any(0x0E00 <= ord(ch) <= 0x0E7F for ch in text):  # Contains Thai characters
                    log.info(f"ğŸ”¤ Thai glyph details:")
                    for i, glyph in enumerate(glyphs[:6]):  # Show first 6 glyphs
                        log.info(f"   [{i}] ID:{glyph['glyph_id']}, cluster:{glyph['cluster']}, "
                                f"advance:{glyph['x_advance']:.1f}, offset:({glyph['x_offset']:.1f},{glyph['y_offset']:.1f})")
                    if len(glyphs) > 6:
                        log.info(f"   ... and {len(glyphs)-6} more glyphs")

                return glyphs
            else:
                log.debug(f"âŒ HarfBuzz shaping failed for '{text}' - falling back to simple processing")
        else:
            # Log why HarfBuzz wasn't used
            reasons = []
            if not font_path:
                reasons.append("no font path")
            if not self.text_shaper.enabled:
                reasons.append("text shaper disabled")
            if len(text) == 0:
                reasons.append("empty text")

            log.debug(f"âš ï¸ Skipping HarfBuzz for '{text}' ({', '.join(reasons)}) - using fallback")

        # Fallback: create simple glyph list for character-by-character processing
        glyphs = []
        for i, ch in enumerate(text):
            if font_name == self.noto_name and self.noto:
                advance = self.noto.char_lengths(ch, scaled_font_size)[0]
            elif hasattr(self, 'fontmap') and font_name in self.fontmap:
                advance = self.fontmap[font_name].char_width(ord(ch)) * scaled_font_size
            else:
                # Default advance when no font info available
                advance = scaled_font_size * 0.6  # Rough estimate

            glyphs.append({
                'glyph_id': ord(ch),
                'cluster': i,
                'x_advance': advance,
                'y_advance': 0.0,
                'x_offset': 0.0,
                'y_offset': 0.0,
                'char_index': i
            })

        # Log fallback info more prominently for Thai text
        if any(0x0E00 <= ord(ch) <= 0x0E7F for ch in text):  # Contains Thai characters
            log.warning(f"âš ï¸ THAI FALLBACK: '{text}' using simple processing instead of HarfBuzz (needs_shaping: {needs_shaping})")
        else:
            log.debug(f"ğŸ“ Fallback processing for '{text}': {len(glyphs)} glyphs (needs_shaping: {needs_shaping})")
        return glyphs

    def receive_layout(self, ltpage: LTPage):
        # æ®µè½
        sstk: list[str] = []            # æ®µè½æ–‡å­—æ ˆ
        pstk: list[Paragraph] = []      # æ®µè½å±æ€§æ ˆ
        vbkt: int = 0                   # æ®µè½å…¬å¼æ‹¬å·è®¡æ•°
        # å…¬å¼ç»„
        vstk: list[LTChar] = []         # å…¬å¼ç¬¦å·ç»„
        vlstk: list[LTLine] = []        # å…¬å¼çº¿æ¡ç»„
        vfix: float = 0                 # å…¬å¼çºµå‘åç§»
        # å…¬å¼ç»„æ ˆ
        var: list[list[LTChar]] = []    # å…¬å¼ç¬¦å·ç»„æ ˆ
        varl: list[list[LTLine]] = []   # å…¬å¼çº¿æ¡ç»„æ ˆ
        varf: list[float] = []          # å…¬å¼çºµå‘åç§»æ ˆ
        vlen: list[float] = []          # å…¬å¼å®½åº¦æ ˆ
        # å…¨å±€
        lstk: list[LTLine] = []         # å…¨å±€çº¿æ¡æ ˆ
        xt: LTChar = None               # ä¸Šä¸€ä¸ªå­—ç¬¦
        xt_cls: int = -1                # ä¸Šä¸€ä¸ªå­—ç¬¦æ‰€å±æ®µè½ï¼Œä¿è¯æ— è®ºç¬¬ä¸€ä¸ªå­—ç¬¦å±äºå“ªä¸ªç±»åˆ«éƒ½å¯ä»¥è§¦å‘æ–°æ®µè½
        vmax: float = ltpage.width / 4  # è¡Œå†…å…¬å¼æœ€å¤§å®½åº¦
        ops: str = ""                   # æ¸²æŸ“ç»“æœ

        def vflag(font: str, char: str):    # åŒ¹é…å…¬å¼ï¼ˆå’Œè§’æ ‡ï¼‰å­—ä½“
            if isinstance(font, bytes):     # ä¸ä¸€å®šèƒ½ decodeï¼Œç›´æ¥è½¬ str
                try:
                    font = font.decode('utf-8')  # å°è¯•ä½¿ç”¨ UTF-8 è§£ç 
                except UnicodeDecodeError:
                    font = ""
            font = font.split("+")[-1]      # å­—ä½“åæˆªæ–­
            if re.match(r"\(cid:", char):
                return True
            # åŸºäºå­—ä½“åè§„åˆ™çš„åˆ¤å®š
            if self.vfont:
                if re.match(self.vfont, font):
                    return True
            else:
                if re.match(                                            # latex å­—ä½“
                    r"(CM[^R]|MS.M|XY|MT|BL|RM|EU|LA|RS|LINE|LCIRCLE|TeX-|rsfs|txsy|wasy|stmary|.*Mono|.*Code|.*Ital|.*Sym|.*Math)",
                    font,
                ):
                    return True
            # åŸºäºå­—ç¬¦é›†è§„åˆ™çš„åˆ¤å®š
            if self.vchar:
                if re.match(self.vchar, char):
                    return True
            else:
                if (
                    char
                    and char != " "                                     # éç©ºæ ¼
                    and (
                        unicodedata.category(char[0])
                        in ["Lm", "Mn", "Sk", "Sm", "Zl", "Zp", "Zs"]   # æ–‡å­—ä¿®é¥°ç¬¦ã€æ•°å­¦ç¬¦å·ã€åˆ†éš”ç¬¦å·
                        or ord(char[0]) in range(0x370, 0x400)          # å¸Œè…Šå­—æ¯
                    )
                ):
                    return True
            return False

        ############################################################
        # A. åŸæ–‡æ¡£è§£æ
        for child in ltpage:
            if isinstance(child, LTChar):
                cur_v = False
                layout = self.layout[ltpage.pageid]
                # ltpage.height å¯èƒ½æ˜¯ fig é‡Œé¢çš„é«˜åº¦ï¼Œè¿™é‡Œç»Ÿä¸€ç”¨ layout.shape
                h, w = layout.shape
                # è¯»å–å½“å‰å­—ç¬¦åœ¨ layout ä¸­çš„ç±»åˆ«
                cx, cy = np.clip(int(child.x0), 0, w - 1), np.clip(int(child.y0), 0, h - 1)
                cls = layout[cy, cx]
                # é”šå®šæ–‡æ¡£ä¸­ bullet çš„ä½ç½®
                if child.get_text() == "â€¢":
                    cls = 0
                # åˆ¤å®šå½“å‰å­—ç¬¦æ˜¯å¦å±äºå…¬å¼
                if (                                                                                        # åˆ¤å®šå½“å‰å­—ç¬¦æ˜¯å¦å±äºå…¬å¼
                    cls == 0                                                                                # 1. ç±»åˆ«ä¸ºä¿ç•™åŒºåŸŸ
                    or (cls == xt_cls and len(sstk[-1].strip()) > 1 and child.size < pstk[-1].size * 0.79)  # 2. è§’æ ‡å­—ä½“ï¼Œæœ‰ 0.76 çš„è§’æ ‡å’Œ 0.799 çš„å¤§å†™ï¼Œè¿™é‡Œç”¨ 0.79 å–ä¸­ï¼ŒåŒæ—¶è€ƒè™‘é¦–å­—æ¯æ”¾å¤§çš„æƒ…å†µ
                    or vflag(child.fontname, child.get_text())                                              # 3. å…¬å¼å­—ä½“
                    or (child.matrix[0] == 0 and child.matrix[3] == 0)                                      # 4. å‚ç›´å­—ä½“
                ):
                    cur_v = True
                # åˆ¤å®šæ‹¬å·ç»„æ˜¯å¦å±äºå…¬å¼
                if not cur_v:
                    if vstk and child.get_text() == "(":
                        cur_v = True
                        vbkt += 1
                    if vbkt and child.get_text() == ")":
                        cur_v = True
                        vbkt -= 1
                if (                                                        # åˆ¤å®šå½“å‰å…¬å¼æ˜¯å¦ç»“æŸ
                    not cur_v                                               # 1. å½“å‰å­—ç¬¦ä¸å±äºå…¬å¼
                    or cls != xt_cls                                        # 2. å½“å‰å­—ç¬¦ä¸å‰ä¸€ä¸ªå­—ç¬¦ä¸å±äºåŒä¸€æ®µè½
                    # or (abs(child.x0 - xt.x0) > vmax and cls != 0)        # 3. æ®µè½å†…æ¢è¡Œï¼Œå¯èƒ½æ˜¯ä¸€é•¿ä¸²æ–œä½“çš„æ®µè½ï¼Œä¹Ÿå¯èƒ½æ˜¯æ®µå†…åˆ†å¼æ¢è¡Œï¼Œè¿™é‡Œè®¾ä¸ªé˜ˆå€¼è¿›è¡ŒåŒºåˆ†
                    # ç¦æ­¢çº¯å…¬å¼ï¼ˆä»£ç ï¼‰æ®µè½æ¢è¡Œï¼Œç›´åˆ°æ–‡å­—å¼€å§‹å†é‡å¼€æ–‡å­—æ®µè½ï¼Œä¿è¯åªå­˜åœ¨ä¸¤ç§æƒ…å†µ
                    # A. çº¯å…¬å¼ï¼ˆä»£ç ï¼‰æ®µè½ï¼ˆé”šå®šç»å¯¹ä½ç½®ï¼‰sstk[-1]=="" -> sstk[-1]=="{v*}"
                    # B. æ–‡å­—å¼€å¤´æ®µè½ï¼ˆæ’ç‰ˆç›¸å¯¹ä½ç½®ï¼‰sstk[-1]!=""
                    or (sstk[-1] != "" and abs(child.x0 - xt.x0) > vmax)    # å› ä¸º cls==xt_cls==0 ä¸€å®šæœ‰ sstk[-1]==""ï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦å†åˆ¤å®š cls!=0
                ):
                    if vstk:
                        if (                                                # æ ¹æ®å…¬å¼å³ä¾§çš„æ–‡å­—ä¿®æ­£å…¬å¼çš„çºµå‘åç§»
                            not cur_v                                       # 1. å½“å‰å­—ç¬¦ä¸å±äºå…¬å¼
                            and cls == xt_cls                               # 2. å½“å‰å­—ç¬¦ä¸å‰ä¸€ä¸ªå­—ç¬¦å±äºåŒä¸€æ®µè½
                            and child.x0 > max([vch.x0 for vch in vstk])    # 3. å½“å‰å­—ç¬¦åœ¨å…¬å¼å³ä¾§
                        ):
                            vfix = vstk[0].y0 - child.y0
                        if sstk[-1] == "":
                            xt_cls = -1 # ç¦æ­¢çº¯å…¬å¼æ®µè½ï¼ˆsstk[-1]=="{v*}"ï¼‰çš„åç»­è¿æ¥ï¼Œä½†æ˜¯è¦è€ƒè™‘æ–°å­—ç¬¦å’Œåç»­å­—ç¬¦çš„è¿æ¥ï¼Œæ‰€ä»¥è¿™é‡Œä¿®æ”¹çš„æ˜¯ä¸Šä¸ªå­—ç¬¦çš„ç±»åˆ«
                        sstk[-1] += f"{{v{len(var)}}}"
                        var.append(vstk)
                        varl.append(vlstk)
                        varf.append(vfix)
                        vstk = []
                        vlstk = []
                        vfix = 0
                # å½“å‰å­—ç¬¦ä¸å±äºå…¬å¼æˆ–å½“å‰å­—ç¬¦æ˜¯å…¬å¼çš„ç¬¬ä¸€ä¸ªå­—ç¬¦
                if not vstk:
                    if cls == xt_cls:               # å½“å‰å­—ç¬¦ä¸å‰ä¸€ä¸ªå­—ç¬¦å±äºåŒä¸€æ®µè½
                        if child.x0 > xt.x1 + 1:    # æ·»åŠ è¡Œå†…ç©ºæ ¼
                            sstk[-1] += " "
                        elif child.x1 < xt.x0:      # æ·»åŠ æ¢è¡Œç©ºæ ¼å¹¶æ ‡è®°åŸæ–‡æ®µè½å­˜åœ¨æ¢è¡Œ
                            sstk[-1] += " "
                            pstk[-1].brk = True
                    else:                           # æ ¹æ®å½“å‰å­—ç¬¦æ„å»ºä¸€ä¸ªæ–°çš„æ®µè½
                        sstk.append("")
                        pstk.append(Paragraph(child.y0, child.x0, child.x0, child.x0, child.y0, child.y1, child.size, False))
                if not cur_v:                                               # æ–‡å­—å…¥æ ˆ
                    if (                                                    # æ ¹æ®å½“å‰å­—ç¬¦ä¿®æ­£æ®µè½å±æ€§
                        child.size > pstk[-1].size                          # 1. å½“å‰å­—ç¬¦æ¯”æ®µè½å­—ä½“å¤§
                        or len(sstk[-1].strip()) == 1                       # 2. å½“å‰å­—ç¬¦ä¸ºæ®µè½ç¬¬äºŒä¸ªæ–‡å­—ï¼ˆè€ƒè™‘é¦–å­—æ¯æ”¾å¤§çš„æƒ…å†µï¼‰
                    ) and child.get_text() != " ":                          # 3. å½“å‰å­—ç¬¦ä¸æ˜¯ç©ºæ ¼
                        pstk[-1].y -= child.size - pstk[-1].size            # ä¿®æ­£æ®µè½åˆå§‹çºµåæ ‡ï¼Œå‡è®¾ä¸¤ä¸ªä¸åŒå¤§å°å­—ç¬¦çš„ä¸Šè¾¹ç•Œå¯¹é½
                        pstk[-1].size = child.size
                    sstk[-1] += child.get_text()
                else:                                                       # å…¬å¼å…¥æ ˆ
                    if (                                                    # æ ¹æ®å…¬å¼å·¦ä¾§çš„æ–‡å­—ä¿®æ­£å…¬å¼çš„çºµå‘åç§»
                        not vstk                                            # 1. å½“å‰å­—ç¬¦æ˜¯å…¬å¼çš„ç¬¬ä¸€ä¸ªå­—ç¬¦
                        and cls == xt_cls                                   # 2. å½“å‰å­—ç¬¦ä¸å‰ä¸€ä¸ªå­—ç¬¦å±äºåŒä¸€æ®µè½
                        and child.x0 > xt.x0                                # 3. å‰ä¸€ä¸ªå­—ç¬¦åœ¨å…¬å¼å·¦ä¾§
                    ):
                        vfix = child.y0 - xt.y0
                    vstk.append(child)
                # æ›´æ–°æ®µè½è¾¹ç•Œï¼Œå› ä¸ºæ®µè½å†…æ¢è¡Œä¹‹åå¯èƒ½æ˜¯å…¬å¼å¼€å¤´ï¼Œæ‰€ä»¥è¦åœ¨å¤–è¾¹å¤„ç†
                pstk[-1].x0 = min(pstk[-1].x0, child.x0)
                pstk[-1].x1 = max(pstk[-1].x1, child.x1)
                pstk[-1].y0 = min(pstk[-1].y0, child.y0)
                pstk[-1].y1 = max(pstk[-1].y1, child.y1)
                # æ›´æ–°ä¸Šä¸€ä¸ªå­—ç¬¦
                xt = child
                xt_cls = cls
            elif isinstance(child, LTFigure):   # å›¾è¡¨
                pass
            elif isinstance(child, LTLine):     # çº¿æ¡
                layout = self.layout[ltpage.pageid]
                # ltpage.height å¯èƒ½æ˜¯ fig é‡Œé¢çš„é«˜åº¦ï¼Œè¿™é‡Œç»Ÿä¸€ç”¨ layout.shape
                h, w = layout.shape
                # è¯»å–å½“å‰çº¿æ¡åœ¨ layout ä¸­çš„ç±»åˆ«
                cx, cy = np.clip(int(child.x0), 0, w - 1), np.clip(int(child.y0), 0, h - 1)
                cls = layout[cy, cx]
                if vstk and cls == xt_cls:      # å…¬å¼çº¿æ¡
                    vlstk.append(child)
                else:                           # å…¨å±€çº¿æ¡
                    lstk.append(child)
            else:
                pass
        # å¤„ç†ç»“å°¾
        if vstk:    # å…¬å¼å‡ºæ ˆ
            sstk[-1] += f"{{v{len(var)}}}"
            var.append(vstk)
            varl.append(vlstk)
            varf.append(vfix)
        log.debug("\n==========[VSTACK]==========\n")
        for id, v in enumerate(var):  # è®¡ç®—å…¬å¼å®½åº¦
            l = max([vch.x1 for vch in v]) - v[0].x0
            log.debug(f'< {l:.1f} {v[0].x0:.1f} {v[0].y0:.1f} {v[0].cid} {v[0].fontname} {len(varl[id])} > v{id} = {"".join([ch.get_text() for ch in v])}')
            vlen.append(l)

        ############################################################
        # B. æ®µè½ç¿»è¯‘
        log.debug("\n==========[SSTACK]==========\n")

        @retry(wait=wait_fixed(1))
        def worker(s: str):  # å¤šçº¿ç¨‹ç¿»è¯‘
            if not s.strip() or re.match(r"^\{v\d+\}$", s):  # ç©ºç™½å’Œå…¬å¼ä¸ç¿»è¯‘
                return s
            try:
                new = self.translator.translate(s)
                return new
            except BaseException as e:
                if log.isEnabledFor(logging.DEBUG):
                    log.exception(e)
                else:
                    log.exception(e, exc_info=False)
                raise e
        with concurrent.futures.ThreadPoolExecutor(
            max_workers=self.thread
        ) as executor:
            news = list(executor.map(worker, sstk))

        ############################################################
        # C. æ–°æ–‡æ¡£æ’ç‰ˆ
        def raw_string(fcur: str, cstk: str):  # ç¼–ç å­—ç¬¦ä¸²
            if fcur == self.noto_name:
                # Apply HarfBuzz shaping for Thai text to get proper glyph IDs
                if (self.text_shaper.enabled and
                    cstk and any(0x0E00 <= ord(ch) <= 0x0E7F for ch in cstk)):

                    try:
                        log.info(f"ğŸ‡¹ğŸ‡­ GLYPH SHAPING: '{cstk}' with HarfBuzz")

                        # Get font path and shape text
                        font_path = self._get_font_path(fcur)
                        if font_path:
                            # Use a reasonable font size for shaping (doesn't affect glyph IDs)
                            shaped = self.text_shaper.shape_text(cstk, font_path, 12.0)

                            if shaped and shaped.success:
                                # Use HarfBuzz glyph IDs instead of default glyph lookup
                                glyph_codes = []
                                for glyph in shaped.glyphs:
                                    glyph_codes.append("%04x" % glyph.glyph_id)

                                log.info(f"âœ… HarfBuzz glyphs: {len(glyph_codes)} glyphs")
                                return "".join(glyph_codes)
                            else:
                                log.debug(f"âŒ HarfBuzz shaping failed, using fallback")

                    except Exception as e:
                        log.warning(f"âš ï¸ Error in glyph shaping: {e}")

                # Fallback to original glyph lookup
                return "".join(["%04x" % self.noto.has_glyph(ord(c)) for c in cstk])

            elif isinstance(self.fontmap[fcur], PDFCIDFont):  # åˆ¤æ–­ç¼–ç é•¿åº¦
                return "".join(["%04x" % ord(c) for c in cstk])
            else:
                return "".join(["%02x" % ord(c) for c in cstk])

        # æ ¹æ®ç›®æ ‡è¯­è¨€è·å–é»˜è®¤è¡Œè·
        LANG_LINEHEIGHT_MAP = {
            "zh-cn": 1.4, "zh-tw": 1.4, "zh-hans": 1.4, "zh-hant": 1.4, "zh": 1.4,
            "ja": 1.1, "ko": 1.2, "en": 1.2, "ar": 1.0, "ru": 0.8, "uk": 0.8, "ta": 0.8,
            "th": 1.5  # Increased line spacing for Thai
        }

        # Check for custom line height from environment/config
        target_lang = self.translator.lang_out.lower()
        env_line_height_key = f"LANG_LINEHEIGHT_{target_lang.upper().replace('-', '_')}"
        custom_line_height = ConfigManager.get(env_line_height_key)

        log.info(f"ğŸ” DEBUG: Checking line height for language '{target_lang}'")
        log.info(f"ğŸ” DEBUG: Looking for config key: {env_line_height_key}")
        log.info(f"ğŸ” DEBUG: Config value found: {custom_line_height}")

        if custom_line_height:
            try:
                default_line_height = float(custom_line_height)
                log.info(f"âœ… DEBUG: Using custom line height: {default_line_height}")
            except (ValueError, TypeError):
                default_line_height = LANG_LINEHEIGHT_MAP.get(target_lang, 1.1)
                log.warning(f"âš ï¸  DEBUG: Invalid line height value, using default: {default_line_height}")
        else:
            default_line_height = LANG_LINEHEIGHT_MAP.get(target_lang, 1.1) # å°è¯­ç§é»˜è®¤1.1
            log.info(f"ğŸ“ DEBUG: No custom line height, using default: {default_line_height}")

        # æ ¹æ®ç›®æ ‡è¯­è¨€è·å–å­—ä½“å¤§å°ç¼©æ”¾æ¯”ä¾‹
        LANG_FONTSIZE_SCALE = {
            "th": 0.7,  # Reduce Thai font size to 90%
        }

        # Check for custom font size scale from environment/config
        env_fontsize_key = f"LANG_FONTSIZE_SCALE_{target_lang.upper().replace('-', '_')}"
        custom_font_scale = ConfigManager.get(env_fontsize_key)

        log.info(f"ğŸ” DEBUG: Checking font scale for language '{target_lang}'")
        log.info(f"ğŸ” DEBUG: Looking for config key: {env_fontsize_key}")
        log.info(f"ğŸ” DEBUG: Config value found: {custom_font_scale}")

        if custom_font_scale:
            try:
                font_size_scale = float(custom_font_scale)
                log.info(f"âœ… DEBUG: Using custom font scale: {font_size_scale}")
            except (ValueError, TypeError):
                font_size_scale = LANG_FONTSIZE_SCALE.get(target_lang, 1.0)
                log.warning(f"âš ï¸  DEBUG: Invalid font scale value, using default: {font_size_scale}")
        else:
            font_size_scale = LANG_FONTSIZE_SCALE.get(target_lang, 1.0)
            log.info(f"ğŸ“ DEBUG: No custom font scale, using default: {font_size_scale}")

        log.info(f"ğŸ¨ DEBUG: Final settings - Font Scale: {font_size_scale}, Line Height: {default_line_height}")

        _x, _y = 0, 0
        ops_list = []

        def gen_op_txt(font, size, x, y, rtxt):
            scaled_size = size * font_size_scale
            if font_size_scale != 1.0:
                log.debug(f"ğŸ“ DEBUG: Scaling font from {size:.2f} to {scaled_size:.2f} (scale: {font_size_scale})")

            return f"/{font} {scaled_size:f} Tf 1 0 0 1 {x:f} {y:f} Tm [<{rtxt}>] TJ "

        def gen_op_line(x, y, xlen, ylen, linewidth):
            return f"ET q 1 0 0 1 {x:f} {y:f} cm [] 0 d 0 J {linewidth:f} w 0 0 m {xlen:f} {ylen:f} l S Q BT "

        for id, new in enumerate(news):
            x: float = pstk[id].x                       # æ®µè½åˆå§‹æ¨ªåæ ‡
            y: float = pstk[id].y                       # æ®µè½åˆå§‹çºµåæ ‡
            x0: float = pstk[id].x0                     # æ®µè½å·¦è¾¹ç•Œ
            x1: float = pstk[id].x1                     # æ®µè½å³è¾¹ç•Œ
            height: float = pstk[id].y1 - pstk[id].y0   # æ®µè½é«˜åº¦
            size: float = pstk[id].size                 # æ®µè½å­—ä½“å¤§å°
            brk: bool = pstk[id].brk                    # æ®µè½æ¢è¡Œæ ‡è®°
            cstk: str = ""                              # å½“å‰æ–‡å­—æ ˆ
            fcur: str = None                            # å½“å‰å­—ä½“ ID
            lidx = 0                                    # è®°å½•æ¢è¡Œæ¬¡æ•°
            tx = x
            fcur_ = fcur
            ptr = 0
            log.debug(f"< {y} {x} {x0} {x1} {size} {brk} > {sstk[id]} | {new}")

            ops_vals: list[dict] = []

            while ptr < len(new):
                vy_regex = re.match(
                    r"\{\s*v([\d\s]+)\}", new[ptr:], re.IGNORECASE
                )  # åŒ¹é… {vn} å…¬å¼æ ‡è®°
                mod = 0  # æ–‡å­—ä¿®é¥°ç¬¦
                if vy_regex:  # åŠ è½½å…¬å¼
                    ptr += len(vy_regex.group(0))
                    try:
                        vid = int(vy_regex.group(1).replace(" ", ""))
                        adv = vlen[vid]
                    except Exception:
                        continue  # ç¿»è¯‘å™¨å¯èƒ½ä¼šè‡ªåŠ¨è¡¥ä¸ªè¶Šç•Œçš„å…¬å¼æ ‡è®°
                    if var[vid][-1].get_text() and unicodedata.category(var[vid][-1].get_text()[0]) in ["Lm", "Mn", "Sk"]:  # æ–‡å­—ä¿®é¥°ç¬¦
                        mod = var[vid][-1].width
                else:  # åŠ è½½æ–‡å­— - Process text with complex script support
                    ch = new[ptr]
                    fcur_ = None
                    try:
                        if self.fontmap["tiro"].to_unichr(ord(ch)) == ch:
                            fcur_ = "tiro"  # é»˜è®¤æ‹‰ä¸å­—ä½“
                    except Exception:
                        pass
                    if fcur_ is None:
                        fcur_ = self.noto_name  # é»˜è®¤éæ‹‰ä¸å­—ä½“

                    # Calculate advancement using scaled font size for proper line width calculation
                    scaled_size_for_width = size * font_size_scale

                    # Try complex text processing for Thai and other complex scripts (temporarily disabled - causes layout issues)
                    if False and fcur_ == self.noto_name and self.text_shaper.enabled and ptr < len(new):
                        # Collect the LONGEST possible text run for optimal shaping
                        text_run = ch
                        lookahead_ptr = ptr + 1

                        # Aggressively collect characters - shape entire sentences when possible
                        # Only stop for: formula markers, font changes, or end of text
                        while lookahead_ptr < len(new):
                            # Check for formula marker
                            if re.match(r"\{\s*v([\d\s]+)\}", new[lookahead_ptr:], re.IGNORECASE):
                                break

                            next_ch = new[lookahead_ptr]
                            next_fcur = None
                            try:
                                if self.fontmap["tiro"].to_unichr(ord(next_ch)) == next_ch:
                                    next_fcur = "tiro"
                            except Exception:
                                pass
                            if next_fcur is None:
                                next_fcur = self.noto_name

                            # Stop if font changes
                            if next_fcur != fcur_:
                                break

                            text_run += next_ch
                            lookahead_ptr += 1

                        # Check if this text run contains complex scripts that need shaping
                        if self.text_shaper._needs_shaping(text_run):
                            # Process the entire run with HarfBuzz - this enables proper contextual shaping
                            glyphs = self._shape_text_run(text_run, fcur_, size, scaled_size_for_width)

                            log.debug(f"ğŸ”¤ Processing complex script sentence: '{text_run}' ({len(text_run)} chars) -> {len(glyphs)} glyphs")

                            # Generate text operations using cluster-based rendering
                            # Group glyphs by cluster to render complete character units
                            clusters = {}
                            total_advance = 0.0

                            # Group glyphs by cluster
                            for glyph in glyphs:
                                cluster = glyph['cluster']
                                if cluster not in clusters:
                                    clusters[cluster] = {
                                        'chars': '',
                                        'base_advance': 0.0,
                                        'x_offset': 0.0,
                                        'y_offset': 0.0,
                                        'char_indices': []
                                    }

                                char_idx = glyph['char_index']
                                if char_idx < len(text_run):
                                    char = text_run[char_idx]

                                    # Build complete character string for this cluster
                                    if char_idx not in clusters[cluster]['char_indices']:
                                        clusters[cluster]['chars'] += char
                                        clusters[cluster]['char_indices'].append(char_idx)

                                    # Track the main advance (from base characters)
                                    char_category = unicodedata.category(char)
                                    if char_category not in ['Mn', 'Mc', 'Me']:  # Not a combining mark
                                        clusters[cluster]['base_advance'] += glyph['x_advance']

                                    # Use positioning from the first glyph in cluster for offset
                                    if len(clusters[cluster]['char_indices']) == 1:
                                        clusters[cluster]['x_offset'] = glyph['x_offset']
                                        clusters[cluster]['y_offset'] = glyph['y_offset']

                            # Generate one text operation per cluster
                            current_x = x
                            for cluster_id in sorted(clusters.keys()):
                                cluster_data = clusters[cluster_id]

                                if cluster_data['chars']:
                                    # Position the complete cluster
                                    cluster_x = current_x + cluster_data['x_offset']
                                    cluster_y = cluster_data['y_offset']

                                    # Create single text operation for the complete character cluster
                                    ops_vals.append({
                                        "type": OpType.TEXT,
                                        "font": fcur_,
                                        "size": size,
                                        "x": cluster_x,
                                        "dy": cluster_y,
                                        "rtxt": raw_string(fcur_, cluster_data['chars']),
                                        "lidx": lidx
                                    })

                                    log.debug(f"ğŸ”¤ Cluster {cluster_id}: '{cluster_data['chars']}' at x={cluster_x:.2f}, y_offset={cluster_y:.2f}, advance={cluster_data['base_advance']:.2f}")

                                    # Advance to next cluster position
                                    current_x += cluster_data['base_advance']
                                    total_advance += cluster_data['base_advance']

                            # Update main x position and pointer
                            x = current_x
                            ptr = lookahead_ptr  # Skip past the processed run
                            adv = 0  # No additional advancement needed
                            fcur = fcur_

                            # Clear text buffer since we processed the run directly
                            cstk = ""
                            continue

                    # Standard character processing (fallback or non-complex scripts)
                    if fcur_ == self.noto_name:
                        adv = self.noto.char_lengths(ch, scaled_size_for_width)[0]
                    else:
                        adv = self.fontmap[fcur_].char_width(ord(ch)) * scaled_size_for_width

                    if font_size_scale != 1.0:
                        if fcur_ == self.noto_name:
                            original_adv = self.noto.char_lengths(ch, size)[0]
                        else:
                            original_adv = self.fontmap[fcur_].char_width(ord(ch)) * size
                        log.debug(f"ğŸ“ DEBUG: Char '{ch}' width scaled from {original_adv:.2f} to {adv:.2f}")

                    ptr += 1
                if (                                # è¾“å‡ºæ–‡å­—ç¼“å†²åŒº
                    fcur_ != fcur                   # 1. å­—ä½“æ›´æ–°
                    or vy_regex                     # 2. æ’å…¥å…¬å¼
                    or (adv > 0 and x + adv > x1 + 0.1 * scaled_size_for_width)    # 3. åˆ°è¾¾å³è¾¹ç•Œï¼ˆå¯èƒ½ä¸€æ•´è¡Œéƒ½è¢«ç¬¦å·åŒ–ï¼Œè¿™é‡Œéœ€è¦è€ƒè™‘æµ®ç‚¹è¯¯å·®ï¼‰
                ):
                    if cstk:
                        ops_vals.append({
                            "type": OpType.TEXT,
                            "font": fcur,
                            "size": size,
                            "x": tx,
                            "dy": 0,
                            "rtxt": raw_string(fcur, cstk),
                            "lidx": lidx
                        })
                        cstk = ""
                if brk and x + adv > x1 + 0.1 * size:  # åˆ°è¾¾å³è¾¹ç•Œä¸”åŸæ–‡æ®µè½å­˜åœ¨æ¢è¡Œ
                    x = x0
                    lidx += 1
                if vy_regex:  # æ’å…¥å…¬å¼
                    fix = 0
                    if fcur is not None:  # æ®µè½å†…å…¬å¼ä¿®æ­£çºµå‘åç§»
                        fix = varf[vid]
                    for vch in var[vid]:  # æ’ç‰ˆå…¬å¼å­—ç¬¦
                        vc = chr(vch.cid)
                        ops_vals.append({
                            "type": OpType.TEXT,
                            "font": self.fontid[vch.font],
                            "size": vch.size,
                            "x": x + vch.x0 - var[vid][0].x0,
                            "dy": fix + vch.y0 - var[vid][0].y0,
                            "rtxt": raw_string(self.fontid[vch.font], vc),
                            "lidx": lidx
                        })
                        if log.isEnabledFor(logging.DEBUG):
                            lstk.append(LTLine(0.1, (_x, _y), (x + vch.x0 - var[vid][0].x0, fix + y + vch.y0 - var[vid][0].y0)))
                            _x, _y = x + vch.x0 - var[vid][0].x0, fix + y + vch.y0 - var[vid][0].y0
                    for l in varl[vid]:  # æ’ç‰ˆå…¬å¼çº¿æ¡
                        if l.linewidth < 5:  # hack æœ‰çš„æ–‡æ¡£ä¼šç”¨ç²—çº¿æ¡å½“å›¾ç‰‡èƒŒæ™¯
                            ops_vals.append({
                                "type": OpType.LINE,
                                "x": l.pts[0][0] + x - var[vid][0].x0,
                                "dy": l.pts[0][1] + fix - var[vid][0].y0,
                                "linewidth": l.linewidth,
                                "xlen": l.pts[1][0] - l.pts[0][0],
                                "ylen": l.pts[1][1] - l.pts[0][1],
                                "lidx": lidx
                            })
                else:  # æ’å…¥æ–‡å­—ç¼“å†²åŒº
                    if not cstk:  # å•è¡Œå¼€å¤´
                        tx = x
                        if x == x0 and ch == " ":  # æ¶ˆé™¤æ®µè½æ¢è¡Œç©ºæ ¼
                            adv = 0
                        else:
                            cstk += ch
                    else:
                        cstk += ch
                adv -= mod # æ–‡å­—ä¿®é¥°ç¬¦
                fcur = fcur_
                x += adv
                if log.isEnabledFor(logging.DEBUG):
                    lstk.append(LTLine(0.1, (_x, _y), (x, y)))
                    _x, _y = x, y
            # å¤„ç†ç»“å°¾
            if cstk:
                ops_vals.append({
                    "type": OpType.TEXT,
                    "font": fcur,
                    "size": size,
                    "x": tx,
                    "dy": 0,
                    "rtxt": raw_string(fcur, cstk),
                    "lidx": lidx
                })

            line_height = default_line_height
            original_line_height = line_height

            while (lidx + 1) * size * line_height > height and line_height >= 1:
                line_height -= 0.05

            if line_height != original_line_height:
                log.debug(f"ğŸ“ DEBUG: Line height auto-adjusted from {original_line_height:.2f} to {line_height:.2f} to fit content")
            else:
                log.debug(f"ğŸ“ DEBUG: Using line height: {line_height:.2f}")

            for vals in ops_vals:
                if vals["type"] == OpType.TEXT:
                    ops_list.append(gen_op_txt(vals["font"], vals["size"], vals["x"], vals["dy"] + y - vals["lidx"] * size * line_height, vals["rtxt"]))
                elif vals["type"] == OpType.LINE:
                    ops_list.append(gen_op_line(vals["x"], vals["dy"] + y - vals["lidx"] * size * line_height, vals["xlen"], vals["ylen"], vals["linewidth"]))

        for l in lstk:  # æ’ç‰ˆå…¨å±€çº¿æ¡
            if l.linewidth < 5:  # hack æœ‰çš„æ–‡æ¡£ä¼šç”¨ç²—çº¿æ¡å½“å›¾ç‰‡èƒŒæ™¯
                ops_list.append(gen_op_line(l.pts[0][0], l.pts[0][1], l.pts[1][0] - l.pts[0][0], l.pts[1][1] - l.pts[0][1], l.linewidth))

        ops = f"BT {''.join(ops_list)}ET "
        return ops


class OpType(Enum):
    TEXT = "text"
    LINE = "line"
